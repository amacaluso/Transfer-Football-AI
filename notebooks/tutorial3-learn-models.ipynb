{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Learn machine learning models\n",
    "\n",
    "This tutorial demonstrates how to learn machine learning models to value on-the-ball actions of football players with the open-source [VAEP framework](https://github.com/ML-KULeuven/socceraction) using the publicly available [Wyscout match event dataset](https://figshare.com/collections/Soccer_match_event_dataset/4415000). The Wyscout dataset includes data for the 2017/2018 English Premier League, the 2017/2018 Spanish Primera División, the 2017/2018 German 1. Bundesliga, the 2017/2018 Italian Serie A, the 2017/2018 French Ligue 1, the 2018 FIFA World Cup, and the UEFA Euro 2016. Covering 1,941 matches, 3,251,294 events and 4,299 players, the dataset is large enough to train machine-learning models and obtain robust ratings for the players.\n",
    "\n",
    "This tutorial demonstrates the following four steps:\n",
    "1. Split the dataset into a training set and a test set.\n",
    "2. Construct the baseline classifiers by using conservative hyperparameters for the learning algorithm.\n",
    "3. Optimize the classifiers by tuning the hyperparameters for the learning algorithm.\n",
    "4. Construct the final classifiers using the optimal hyperparameters for the learning algorithm.\n",
    "\n",
    "This notebook is compatible with `socceraction` version `0.2.0`.\n",
    "\n",
    "**Conventions:**\n",
    "* Variables that refer a `DataFrame` object are prefixed with `df_`.\n",
    "* Variables that refer a collection of `DataFrame` objects (e.g., a list, a set or a dict) are prefixed with `dfs_`.\n",
    "\n",
    "**References:**\n",
    "* Tom Decroos, Lotte Bransen, Jan Van Haaren, and Jesse Davis. \"[Actions Speak Louder than Goals: Valuing Player Actions in Soccer.](https://arxiv.org/abs/1802.07127)\" In *Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining*, pp. 1851-1861. 2019.\n",
    "* Luca Pappalardo, Paolo Cintia, Alessio Rossi, Emanuele Massucco, Paolo Ferragina, Dino Pedreschi, and Fosca Giannotti. \"[A Public Data Set of Spatio-Temporal Match Events in Soccer Competitions.](https://www.nature.com/articles/s41597-019-0247-7)\" *Scientific Data 6*, no. 1 (2019): 1-15."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional:** If you run this notebook on Google Colab, then uncomment the code in the following cell and execute the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tables==3.6.1\n",
    "# !pip install scikit-plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional:** If you run this notebook on Google Colab and wish to store all data in a Google Drive folder, then uncomment the code in the following cell and execute the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "# %mkdir -p '/content/gdrive/My Drive/Friends of Tracking/'\n",
    "# %cd '/content/gdrive/My Drive/Friends of Tracking/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
    "from sklearn.metrics import brier_score_loss, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Helper function to plot calibration curve\n",
    "def plot_calibration_curve(y_true, probas_list, clf_names, n_bins=10, ax=None):\n",
    "    \"\"\"Plot calibration curve using sklearn's calibration_curve\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    for probas, name in zip(probas_list, clf_names):\n",
    "        fraction_of_positives, mean_predicted_value = calibration_curve(\n",
    "            y_true, probas, n_bins=n_bins, strategy='uniform'\n",
    "        )\n",
    "        ax.plot(mean_predicted_value, fraction_of_positives, 's-', label=name)\n",
    "    \n",
    "    ax.plot([0, 1], [0, 1], 'k--', label='Perfectly calibrated')\n",
    "    ax.set_xlabel('Mean predicted probability')\n",
    "    ax.set_ylabel('Fraction of positives')\n",
    "    ax.set_ylim([-0.05, 1.05])\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.set_title('Calibration plots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore', category=pd.io.pytables.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This third tutorial assumes that the `spadl.h5` HDF5 file as well as the `features.h5` and `labels.h5` files have been created for a set of games in the first or second tutorial.\n",
    "\n",
    "This third tutorial only uses features that have been generated in the first tutorial. However, you are strongly encouraged to toy around with the additional features from the second tutorial and to try out your own features to improve the accuracy of the predictive machine learning models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_games = pd.read_hdf('spadl.h5', key='games')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional:** If you plan to produce results for a particular season in the Wyscout match event dataset (e.g., 2017/2018 English Premier League), you should consider leaving that season out of the dataset to avoid the same game states from appearing in both the training set and the test set. If you would like to only include a particular subset of games, then uncomment the code in the following cell, adapt the selector and execute the cell. The example selector will select all games that were played in the 2017/2018 English Premier League."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_games = df_games[\n",
    "#     df_games['competition_id'] == 364\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>roundId</th>\n",
       "      <th>gameweek</th>\n",
       "      <th>teamsData</th>\n",
       "      <th>seasonId</th>\n",
       "      <th>dateutc</th>\n",
       "      <th>winner</th>\n",
       "      <th>venue</th>\n",
       "      <th>wyId</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "      <th>referees</th>\n",
       "      <th>duration</th>\n",
       "      <th>competitionId</th>\n",
       "      <th>groupName</th>\n",
       "      <th>game_id</th>\n",
       "      <th>home_team_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Played</td>\n",
       "      <td>4165363</td>\n",
       "      <td>1</td>\n",
       "      <td>{'3148': {'scoreET': 0, 'coachId': 134365, 'si...</td>\n",
       "      <td>10078</td>\n",
       "      <td>2018-06-17 15:00:00</td>\n",
       "      <td>15473</td>\n",
       "      <td>Stadion Luzhniki</td>\n",
       "      <td>2057984</td>\n",
       "      <td>Germany - Mexico, 0 - 1</td>\n",
       "      <td>2018-06-17 17:00:00-02:00</td>\n",
       "      <td>[{'refereeId': 380599, 'role': 'referee'}, {'r...</td>\n",
       "      <td>Regular</td>\n",
       "      <td>28</td>\n",
       "      <td>Group F</td>\n",
       "      <td>2057984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Played</td>\n",
       "      <td>4165363</td>\n",
       "      <td>1</td>\n",
       "      <td>{'16871': {'scoreET': 0, 'coachId': 484354, 's...</td>\n",
       "      <td>10078</td>\n",
       "      <td>2018-06-17 12:00:00</td>\n",
       "      <td>17322</td>\n",
       "      <td>Samara Arena</td>\n",
       "      <td>2057979</td>\n",
       "      <td>Costa Rica - Serbia, 0 - 1</td>\n",
       "      <td>2018-06-17 14:00:00-02:00</td>\n",
       "      <td>[{'refereeId': 407722, 'role': 'referee'}, {'r...</td>\n",
       "      <td>Regular</td>\n",
       "      <td>28</td>\n",
       "      <td>Group E</td>\n",
       "      <td>2057979</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Played</td>\n",
       "      <td>4165363</td>\n",
       "      <td>1</td>\n",
       "      <td>{'16823': {'scoreET': 0, 'coachId': 142913, 's...</td>\n",
       "      <td>10078</td>\n",
       "      <td>2018-06-16 19:00:00</td>\n",
       "      <td>9598</td>\n",
       "      <td>Kaliningrad Stadium</td>\n",
       "      <td>2057973</td>\n",
       "      <td>Croatia - Nigeria, 2 - 0</td>\n",
       "      <td>2018-06-16 21:00:00-02:00</td>\n",
       "      <td>[{'refereeId': 378204, 'role': 'referee'}, {'r...</td>\n",
       "      <td>Regular</td>\n",
       "      <td>28</td>\n",
       "      <td>Group D</td>\n",
       "      <td>2057973</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Played</td>\n",
       "      <td>4165363</td>\n",
       "      <td>1</td>\n",
       "      <td>{'7712': {'scoreET': 0, 'coachId': 54577, 'sid...</td>\n",
       "      <td>10078</td>\n",
       "      <td>2018-06-16 16:00:00</td>\n",
       "      <td>7712</td>\n",
       "      <td>Mordovia Arena</td>\n",
       "      <td>2057967</td>\n",
       "      <td>Peru - Denmark, 0 - 1</td>\n",
       "      <td>2018-06-16 18:00:00-02:00</td>\n",
       "      <td>[{'refereeId': 407901, 'role': 'referee'}, {'r...</td>\n",
       "      <td>Regular</td>\n",
       "      <td>28</td>\n",
       "      <td>Group C</td>\n",
       "      <td>2057967</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Played</td>\n",
       "      <td>4165363</td>\n",
       "      <td>1</td>\n",
       "      <td>{'7839': {'scoreET': 0, 'coachId': 57369, 'sid...</td>\n",
       "      <td>10078</td>\n",
       "      <td>2018-06-16 13:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Otkrytiye Arena</td>\n",
       "      <td>2057972</td>\n",
       "      <td>Argentina - Iceland, 1 - 1</td>\n",
       "      <td>2018-06-16 15:00:00-02:00</td>\n",
       "      <td>[{'refereeId': 384987, 'role': 'referee'}, {'r...</td>\n",
       "      <td>Regular</td>\n",
       "      <td>28</td>\n",
       "      <td>Group D</td>\n",
       "      <td>2057972</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Played</td>\n",
       "      <td>4165363</td>\n",
       "      <td>1</td>\n",
       "      <td>{'8493': {'scoreET': 0, 'coachId': 134090, 'si...</td>\n",
       "      <td>10078</td>\n",
       "      <td>2018-06-16 10:00:00</td>\n",
       "      <td>4418</td>\n",
       "      <td>Kazan' Arena</td>\n",
       "      <td>2057966</td>\n",
       "      <td>France - Australia, 2 - 1</td>\n",
       "      <td>2018-06-16 12:00:00-02:00</td>\n",
       "      <td>[{'refereeId': 378232, 'role': 'referee'}, {'r...</td>\n",
       "      <td>Regular</td>\n",
       "      <td>28</td>\n",
       "      <td>Group C</td>\n",
       "      <td>2057966</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Played</td>\n",
       "      <td>4165363</td>\n",
       "      <td>1</td>\n",
       "      <td>{'9905': {'scoreET': 0, 'coachId': 137521, 'si...</td>\n",
       "      <td>10078</td>\n",
       "      <td>2018-06-15 18:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Olimpiyskiy Stadion Fisht</td>\n",
       "      <td>2057960</td>\n",
       "      <td>Portugal - Spain, 3 - 3</td>\n",
       "      <td>2018-06-15 20:00:00-02:00</td>\n",
       "      <td>[{'refereeId': 377206, 'role': 'referee'}, {'r...</td>\n",
       "      <td>Regular</td>\n",
       "      <td>28</td>\n",
       "      <td>Group B</td>\n",
       "      <td>2057960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Played</td>\n",
       "      <td>4165363</td>\n",
       "      <td>1</td>\n",
       "      <td>{'10840': {'scoreET': 0, 'coachId': 136612, 's...</td>\n",
       "      <td>10078</td>\n",
       "      <td>2018-06-15 15:00:00</td>\n",
       "      <td>10840</td>\n",
       "      <td>Stadion Krestovskyi</td>\n",
       "      <td>2057961</td>\n",
       "      <td>Morocco - Iran, 0 - 1</td>\n",
       "      <td>2018-06-15 17:00:00-02:00</td>\n",
       "      <td>[{'refereeId': 384995, 'role': 'referee'}, {'r...</td>\n",
       "      <td>Regular</td>\n",
       "      <td>28</td>\n",
       "      <td>Group B</td>\n",
       "      <td>2057961</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Played</td>\n",
       "      <td>4165363</td>\n",
       "      <td>1</td>\n",
       "      <td>{'16129': {'scoreET': 0, 'coachId': 33204, 'si...</td>\n",
       "      <td>10078</td>\n",
       "      <td>2018-06-15 12:00:00</td>\n",
       "      <td>15670</td>\n",
       "      <td>Stadion Central'nyj</td>\n",
       "      <td>2057955</td>\n",
       "      <td>Egypt - Uruguay, 0 - 1</td>\n",
       "      <td>2018-06-15 14:00:00-02:00</td>\n",
       "      <td>[{'refereeId': 377215, 'role': 'referee'}, {'r...</td>\n",
       "      <td>Regular</td>\n",
       "      <td>28</td>\n",
       "      <td>Group A</td>\n",
       "      <td>2057955</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Played</td>\n",
       "      <td>4165363</td>\n",
       "      <td>1</td>\n",
       "      <td>{'14358': {'scoreET': 0, 'coachId': 264893, 's...</td>\n",
       "      <td>10078</td>\n",
       "      <td>2018-06-14 15:00:00</td>\n",
       "      <td>14358</td>\n",
       "      <td>Olimpiyskiy stadion Luzhniki</td>\n",
       "      <td>2057954</td>\n",
       "      <td>Russia - Saudi Arabia, 5 - 0</td>\n",
       "      <td>2018-06-14 17:00:00-02:00</td>\n",
       "      <td>[{'refereeId': 378051, 'role': 'referee'}, {'r...</td>\n",
       "      <td>Regular</td>\n",
       "      <td>28</td>\n",
       "      <td>Group A</td>\n",
       "      <td>2057954</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    status  roundId  gameweek  \\\n",
       "54  Played  4165363         1   \n",
       "55  Played  4165363         1   \n",
       "56  Played  4165363         1   \n",
       "57  Played  4165363         1   \n",
       "58  Played  4165363         1   \n",
       "59  Played  4165363         1   \n",
       "60  Played  4165363         1   \n",
       "61  Played  4165363         1   \n",
       "62  Played  4165363         1   \n",
       "63  Played  4165363         1   \n",
       "\n",
       "                                            teamsData  seasonId  \\\n",
       "54  {'3148': {'scoreET': 0, 'coachId': 134365, 'si...     10078   \n",
       "55  {'16871': {'scoreET': 0, 'coachId': 484354, 's...     10078   \n",
       "56  {'16823': {'scoreET': 0, 'coachId': 142913, 's...     10078   \n",
       "57  {'7712': {'scoreET': 0, 'coachId': 54577, 'sid...     10078   \n",
       "58  {'7839': {'scoreET': 0, 'coachId': 57369, 'sid...     10078   \n",
       "59  {'8493': {'scoreET': 0, 'coachId': 134090, 'si...     10078   \n",
       "60  {'9905': {'scoreET': 0, 'coachId': 137521, 'si...     10078   \n",
       "61  {'10840': {'scoreET': 0, 'coachId': 136612, 's...     10078   \n",
       "62  {'16129': {'scoreET': 0, 'coachId': 33204, 'si...     10078   \n",
       "63  {'14358': {'scoreET': 0, 'coachId': 264893, 's...     10078   \n",
       "\n",
       "                dateutc  winner                         venue     wyId  \\\n",
       "54  2018-06-17 15:00:00   15473              Stadion Luzhniki  2057984   \n",
       "55  2018-06-17 12:00:00   17322                  Samara Arena  2057979   \n",
       "56  2018-06-16 19:00:00    9598           Kaliningrad Stadium  2057973   \n",
       "57  2018-06-16 16:00:00    7712                Mordovia Arena  2057967   \n",
       "58  2018-06-16 13:00:00       0               Otkrytiye Arena  2057972   \n",
       "59  2018-06-16 10:00:00    4418                  Kazan' Arena  2057966   \n",
       "60  2018-06-15 18:00:00       0     Olimpiyskiy Stadion Fisht  2057960   \n",
       "61  2018-06-15 15:00:00   10840           Stadion Krestovskyi  2057961   \n",
       "62  2018-06-15 12:00:00   15670           Stadion Central'nyj  2057955   \n",
       "63  2018-06-14 15:00:00   14358  Olimpiyskiy stadion Luzhniki  2057954   \n",
       "\n",
       "                           label                       date  \\\n",
       "54       Germany - Mexico, 0 - 1  2018-06-17 17:00:00-02:00   \n",
       "55    Costa Rica - Serbia, 0 - 1  2018-06-17 14:00:00-02:00   \n",
       "56      Croatia - Nigeria, 2 - 0  2018-06-16 21:00:00-02:00   \n",
       "57         Peru - Denmark, 0 - 1  2018-06-16 18:00:00-02:00   \n",
       "58    Argentina - Iceland, 1 - 1  2018-06-16 15:00:00-02:00   \n",
       "59     France - Australia, 2 - 1  2018-06-16 12:00:00-02:00   \n",
       "60       Portugal - Spain, 3 - 3  2018-06-15 20:00:00-02:00   \n",
       "61         Morocco - Iran, 0 - 1  2018-06-15 17:00:00-02:00   \n",
       "62        Egypt - Uruguay, 0 - 1  2018-06-15 14:00:00-02:00   \n",
       "63  Russia - Saudi Arabia, 5 - 0  2018-06-14 17:00:00-02:00   \n",
       "\n",
       "                                             referees duration  competitionId  \\\n",
       "54  [{'refereeId': 380599, 'role': 'referee'}, {'r...  Regular             28   \n",
       "55  [{'refereeId': 407722, 'role': 'referee'}, {'r...  Regular             28   \n",
       "56  [{'refereeId': 378204, 'role': 'referee'}, {'r...  Regular             28   \n",
       "57  [{'refereeId': 407901, 'role': 'referee'}, {'r...  Regular             28   \n",
       "58  [{'refereeId': 384987, 'role': 'referee'}, {'r...  Regular             28   \n",
       "59  [{'refereeId': 378232, 'role': 'referee'}, {'r...  Regular             28   \n",
       "60  [{'refereeId': 377206, 'role': 'referee'}, {'r...  Regular             28   \n",
       "61  [{'refereeId': 384995, 'role': 'referee'}, {'r...  Regular             28   \n",
       "62  [{'refereeId': 377215, 'role': 'referee'}, {'r...  Regular             28   \n",
       "63  [{'refereeId': 378051, 'role': 'referee'}, {'r...  Regular             28   \n",
       "\n",
       "   groupName  game_id  home_team_id  \n",
       "54   Group F  2057984             0  \n",
       "55   Group E  2057979             0  \n",
       "56   Group D  2057973             0  \n",
       "57   Group C  2057967             0  \n",
       "58   Group D  2057972             0  \n",
       "59   Group C  2057966             0  \n",
       "60   Group B  2057960             0  \n",
       "61   Group B  2057961             0  \n",
       "62   Group A  2057955             0  \n",
       "63   Group A  2057954             0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_games.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the *features* for the selected games and combine them into the `df_features` `DataFrame` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a700d8a647cf4b348da8bec5decf5a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/495 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfs_features = []\n",
    "for _, game in tqdm(df_games.iterrows(), total=len(df_games)):\n",
    "    game_id = game['game_id']\n",
    "    df_features = pd.read_hdf('features.h5', key=f'game_{game_id}')\n",
    "    df_features['game_id'] = game_id\n",
    "    dfs_features.append(df_features)\n",
    "df_features = pd.concat(dfs_features).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id-0</th>\n",
       "      <th>period_id-0</th>\n",
       "      <th>time_seconds-0</th>\n",
       "      <th>team_id-0</th>\n",
       "      <th>player_id-0</th>\n",
       "      <th>start_x-0</th>\n",
       "      <th>start_y-0</th>\n",
       "      <th>end_x-0</th>\n",
       "      <th>end_y-0</th>\n",
       "      <th>bodypart_id-0</th>\n",
       "      <th>...</th>\n",
       "      <th>end_x_norm-2</th>\n",
       "      <th>end_y_norm-2</th>\n",
       "      <th>end_distance_to_goal-2</th>\n",
       "      <th>end_angle_to_goal-2</th>\n",
       "      <th>xdiff_sequence_pre</th>\n",
       "      <th>ydiff_sequence_pre</th>\n",
       "      <th>time_sequence_pre</th>\n",
       "      <th>xdiff_sequence_post</th>\n",
       "      <th>ydiff_sequence_post</th>\n",
       "      <th>game_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>808548</th>\n",
       "      <td>2057954</td>\n",
       "      <td>1</td>\n",
       "      <td>2863.131899</td>\n",
       "      <td>14358</td>\n",
       "      <td>4513</td>\n",
       "      <td>66</td>\n",
       "      <td>33</td>\n",
       "      <td>53</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580952</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>49.193496</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.588698</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2057954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808549</th>\n",
       "      <td>2057954</td>\n",
       "      <td>1</td>\n",
       "      <td>2863.807114</td>\n",
       "      <td>16521</td>\n",
       "      <td>122577</td>\n",
       "      <td>47</td>\n",
       "      <td>62</td>\n",
       "      <td>31</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.514706</td>\n",
       "      <td>66.007575</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.088065</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2057954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808550</th>\n",
       "      <td>2057954</td>\n",
       "      <td>1</td>\n",
       "      <td>2865.964868</td>\n",
       "      <td>14358</td>\n",
       "      <td>220971</td>\n",
       "      <td>69</td>\n",
       "      <td>64</td>\n",
       "      <td>73</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.504762</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>52.153619</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.832969</td>\n",
       "      <td>7.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2057954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808551</th>\n",
       "      <td>2057954</td>\n",
       "      <td>1</td>\n",
       "      <td>2868.496551</td>\n",
       "      <td>14358</td>\n",
       "      <td>103682</td>\n",
       "      <td>73</td>\n",
       "      <td>72</td>\n",
       "      <td>78</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704762</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>31.064449</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>4.689437</td>\n",
       "      <td>20.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2057954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808552</th>\n",
       "      <td>2057954</td>\n",
       "      <td>1</td>\n",
       "      <td>2870.980334</td>\n",
       "      <td>14358</td>\n",
       "      <td>257800</td>\n",
       "      <td>78</td>\n",
       "      <td>70</td>\n",
       "      <td>77</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.695238</td>\n",
       "      <td>1.058824</td>\n",
       "      <td>49.678969</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.015466</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2057954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808553</th>\n",
       "      <td>2057954</td>\n",
       "      <td>1</td>\n",
       "      <td>2870.980334</td>\n",
       "      <td>16521</td>\n",
       "      <td>122577</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>-0.029412</td>\n",
       "      <td>85.906926</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2.483783</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2057954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808554</th>\n",
       "      <td>2057954</td>\n",
       "      <td>1</td>\n",
       "      <td>2872.843120</td>\n",
       "      <td>16521</td>\n",
       "      <td>122577</td>\n",
       "      <td>23</td>\n",
       "      <td>37</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.073529</td>\n",
       "      <td>82.280010</td>\n",
       "      <td>2.655172</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.862786</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2057954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808555</th>\n",
       "      <td>2057954</td>\n",
       "      <td>1</td>\n",
       "      <td>2939.438099</td>\n",
       "      <td>14358</td>\n",
       "      <td>257800</td>\n",
       "      <td>81</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.780952</td>\n",
       "      <td>0.455882</td>\n",
       "      <td>23.194827</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>68.457765</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>2057954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808556</th>\n",
       "      <td>2057954</td>\n",
       "      <td>1</td>\n",
       "      <td>2943.061365</td>\n",
       "      <td>16521</td>\n",
       "      <td>122561</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>19</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209524</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>83.096330</td>\n",
       "      <td>20.750000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>70.218245</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>2057954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808557</th>\n",
       "      <td>2057954</td>\n",
       "      <td>1</td>\n",
       "      <td>2983.382036</td>\n",
       "      <td>16521</td>\n",
       "      <td>122623</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>43.943937</td>\n",
       "      <td>76.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2057954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        game_id-0  period_id-0  time_seconds-0  team_id-0  player_id-0  \\\n",
       "808548    2057954            1     2863.131899      14358         4513   \n",
       "808549    2057954            1     2863.807114      16521       122577   \n",
       "808550    2057954            1     2865.964868      14358       220971   \n",
       "808551    2057954            1     2868.496551      14358       103682   \n",
       "808552    2057954            1     2870.980334      14358       257800   \n",
       "808553    2057954            1     2870.980334      16521       122577   \n",
       "808554    2057954            1     2872.843120      16521       122577   \n",
       "808555    2057954            1     2939.438099      14358       257800   \n",
       "808556    2057954            1     2943.061365      16521       122561   \n",
       "808557    2057954            1     2983.382036      16521       122623   \n",
       "\n",
       "        start_x-0  start_y-0  end_x-0  end_y-0  bodypart_id-0  ...  \\\n",
       "808548         66         33       53       38              0  ...   \n",
       "808549         47         62       31       36              0  ...   \n",
       "808550         69         64       73       72              0  ...   \n",
       "808551         73         72       78       70              0  ...   \n",
       "808552         78         70       77       63              0  ...   \n",
       "808553         22         30       23       37              0  ...   \n",
       "808554         23         37       22       30              0  ...   \n",
       "808555         81         67        0        0              0  ...   \n",
       "808556        100        100       19       33              0  ...   \n",
       "808557         50         50      100      100              0  ...   \n",
       "\n",
       "        end_x_norm-2  end_y_norm-2 end_distance_to_goal-2 end_angle_to_goal-2  \\\n",
       "808548      0.580952      0.176471              49.193496            2.000000   \n",
       "808549      0.371429      0.514706              66.007575           66.000000   \n",
       "808550      0.504762      0.558824              52.153619           13.000000   \n",
       "808551      0.704762      0.470588              31.064449           15.500000   \n",
       "808552      0.695238      1.058824              49.678969            0.842105   \n",
       "808553      0.257143     -0.029412              85.906926            2.166667   \n",
       "808554      0.266667      0.073529              82.280010            2.655172   \n",
       "808555      0.780952      0.455882              23.194827            7.666667   \n",
       "808556      0.209524      0.441176              83.096330           20.750000   \n",
       "808557      1.000000      1.000000              34.000000            0.000000   \n",
       "\n",
       "       xdiff_sequence_pre  ydiff_sequence_pre  time_sequence_pre  \\\n",
       "808548                5.0                26.0           2.588698   \n",
       "808549               -2.0                38.0           2.088065   \n",
       "808550                3.0                31.0           2.832969   \n",
       "808551               15.0                66.0           4.689437   \n",
       "808552                9.0                 6.0           5.015466   \n",
       "808553              -10.0                34.0           2.483783   \n",
       "808554               -4.0                39.0           1.862786   \n",
       "808555               -2.0                29.0          68.457765   \n",
       "808556               77.0                63.0          70.218245   \n",
       "808557               26.0                49.0          43.943937   \n",
       "\n",
       "        xdiff_sequence_post  ydiff_sequence_post  game_id  \n",
       "808548                 -8.0                 31.0  2057954  \n",
       "808549                -18.0                 12.0  2057954  \n",
       "808550                  7.0                 39.0  2057954  \n",
       "808551                 20.0                 64.0  2057954  \n",
       "808552                  8.0                 -1.0  2057954  \n",
       "808553                 -9.0                 41.0  2057954  \n",
       "808554                 -5.0                 32.0  2057954  \n",
       "808555                -83.0                -38.0  2057954  \n",
       "808556                 -4.0                 -4.0  2057954  \n",
       "808557                 76.0                 99.0  2057954  \n",
       "\n",
       "[10 rows x 89 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the *labels* for the selected games and combine them into the `df_labels` `DataFrame` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2061e5e3982454f93a5c87faacd7e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/495 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfs_labels = []\n",
    "for _, game in tqdm(df_games.iterrows(), total=len(df_games)):\n",
    "    game_id = game['game_id']  \n",
    "    df_labels = pd.read_hdf('labels.h5', key=f'game_{game_id}')\n",
    "    df_labels['game_id'] = game_id\n",
    "    dfs_labels.append(df_labels)\n",
    "df_labels = pd.concat(dfs_labels).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df_labels.tail==True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To accurately predict the labels for game states, the challenge is to train a robust machine learning model that generalizes well from *observed* game states (e.g., game states in games that have been played already) to *unobserved* game states (e.g., game states in games that are yet to be played). Hence, the machine learning model needs to capture interactions between features of game states that are not too specific to identify *similar* game states yet specific enough to distinguish between *dissimilar* game states.\n",
    "\n",
    "Typically, a machine learning model is said to be *overfitted* on the data if the interactions are too specific (i.e., apply to just a few game states) and is said to be *underfitted* on the data if the interactions are too general (i.e., apply to about all game states). To avoid underfitting, we define an expressive set of features and use a machine learning algorithm that learns a model that can capture complex relationships between these features. To avoid overfitting, we apply [cross-validation](https://scikit-learn.org/stable/modules/cross_validation.html) to assess how well a candidate model would perform in practice and apply regularization techniques to keep the learned model as simple as possible.\n",
    "\n",
    "In this tutorial, we will apply the following methodology:\n",
    "1. Split the available data into a training set and a test set. The training set will be used to learn the machine learning model, whereas the test set will be kept aside until the very end to assess the real-world performance of the learned model.\n",
    "2. Learn models with different values for the hyperparameters of the learning algorithm on the training set by adopting a $k$-fold cross-validation setup:\n",
    "  * Split the training set in $k$ random folds or subsets of equal size.\n",
    "  * Use $k$-1 training folds to train the model and compute the evaluation metric on the remaining validation fold.\n",
    "  * Repeat $k$ times until each fold has served as the validation fold once.\n",
    "3. Select the values for the hyperparameters that yield the best performance across the $k$ validation folds according to the evaluation metric.\n",
    "4. Train the final model on the full training set using the optimal values for the hyperparameters.\n",
    "5. Apply the final model on the test set and compute the evaluation metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell splits the available data into a training set and test set using the `train_test_split` function.\n",
    "\n",
    "* **Test set size:** The `test_size` parameter controls the number of examples in the test set. The challenge is to find an appropriate balance between the number of training examples and the number of test examples. Typically, more training examples yield better models, whereas more test examples yield more reliable evaluation metrics.\n",
    "* **Random state:** The `random_state` parameter sets the *seed* for the random number generator. By setting a *seed*, the train-test split will be the same for each execution of the `train_test_split` function, which is important for reproducing the results and comparing different models.\n",
    "* **Stratification:** The `stratify` parameter enforces a *stratified* train-test split according to the provided class label. By doing so, the distribution of the provided class label will be the same in the training set and the test set, which can be helpful to obtain a well-calibrated model. Since we will be using two different class labels (i.e., `scores` and `concedes`), we use a concatenation of both class labels for the stratification procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train, df_X_test, df_y_train, df_y_test = train_test_split(\n",
    "    df_features,\n",
    "    df_labels,\n",
    "    test_size=0.10,\n",
    "    random_state=42,\n",
    "    stratify=df_labels['scores'].astype(str) + '_' + df_labels['concedes'].astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells inspect whether the training set and test set have the same proportion of positive and negative examples for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_train['scores'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_test['scores'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_train['concedes'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_test['concedes'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** In a real-world scenario where more data is available, you should consider respecting the chronological order of the games to construct the training set, validation set and test set. For instance, use the data for the 2016/2017 and 2017/2018 seasons to train the models, use the data for the 2018/2019 season to tune the models, and use the data for the 2019/2020 season to obtain the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct baseline classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell provides a list of features that the machine learning algorithm will consider to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'start_distance_to_goal-0',\n",
    "    'end_distance_to_goal-0',\n",
    "    'start_distance_to_goal-1',\n",
    "    'end_distance_to_goal-1',\n",
    "    'start_distance_to_goal-2',\n",
    "    'end_distance_to_goal-2',\n",
    "    'start_angle_to_goal-0',\n",
    "    'end_angle_to_goal-0',\n",
    "    'start_angle_to_goal-1',\n",
    "    'end_angle_to_goal-1',\n",
    "    'start_angle_to_goal-2',\n",
    "    'end_angle_to_goal-2',\n",
    "    'team-1',\n",
    "    'team-2'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell provides a list of class labels for which the machine learning algorithm will train a model.\n",
    "\n",
    "**Note:** The `concedes` class label has been commented to speed up the execution of the entire notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    'scores',\n",
    "#     'concedes'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell trains an XGBoost classifier for each label using *conservative* hyperparamters for the learning algorithm, which will serve as *baseline* models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db2f8fed11264e6e9a5be5e914cd7701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anma10\\PycharmProjects\\fot-valuing-actions\\venv\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [11:54:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 17.4 s\n",
      "Wall time: 718 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "models = {}\n",
    "for label in tqdm(labels):\n",
    "    model = XGBClassifier(\n",
    "        eval_metric='logloss',\n",
    "        use_label_encoder=False,\n",
    "        n_estimators=10,\n",
    "        max_depth=3,\n",
    "        base_score=0.5\n",
    "    )\n",
    "    model.fit(\n",
    "        X=df_X_train[features],\n",
    "        y=df_y_train[label]\n",
    "    )\n",
    "    models[label] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell estimates the probabilities for each label using the trained *baseline* models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6148d9381f4147aa95eace607abd3de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfs_predictions = {}\n",
    "for label in tqdm(labels):\n",
    "    model = models[label]\n",
    "    probabilities = model.predict_proba(\n",
    "        df_X_test[features]\n",
    "    )\n",
    "    predictions = probabilities[:, 1]\n",
    "    dfs_predictions[label] = pd.Series(predictions, index=df_X_test.index)\n",
    "df_predictions = pd.concat(dfs_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199132</th>\n",
       "      <td>0.022262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216937</th>\n",
       "      <td>0.022262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26770</th>\n",
       "      <td>0.022262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666573</th>\n",
       "      <td>0.022262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630527</th>\n",
       "      <td>0.022262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50082</th>\n",
       "      <td>0.022262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550648</th>\n",
       "      <td>0.022262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552616</th>\n",
       "      <td>0.022262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93778</th>\n",
       "      <td>0.022262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655439</th>\n",
       "      <td>0.022262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80856 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          scores\n",
       "199132  0.022262\n",
       "216937  0.022262\n",
       "26770   0.022262\n",
       "666573  0.022262\n",
       "630527  0.022262\n",
       "...          ...\n",
       "50082   0.022262\n",
       "550648  0.022262\n",
       "552616  0.022262\n",
       "93778   0.022262\n",
       "655439  0.022262\n",
       "\n",
       "[80856 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features in training set: ['start_distance_to_goal-0', 'end_distance_to_goal-0', 'start_distance_to_goal-1', 'end_distance_to_goal-1', 'start_distance_to_goal-2', 'end_distance_to_goal-2', 'start_angle_to_goal-0', 'end_angle_to_goal-0', 'start_angle_to_goal-1', 'end_angle_to_goal-1', 'start_angle_to_goal-2', 'end_angle_to_goal-2', 'team-1', 'team-2']\n",
      "Missing features: []\n",
      "\n",
      "Feature stats:\n",
      "       start_distance_to_goal-0  end_distance_to_goal-0  \\\n",
      "count             727702.000000           727702.000000   \n",
      "mean                  66.764707               64.602527   \n",
      "std                   22.378271               23.133267   \n",
      "min                    5.000000                5.000000   \n",
      "25%                   50.447993               47.507894   \n",
      "50%                   67.742158               66.128662   \n",
      "75%                   82.800966               80.056230   \n",
      "max                  124.020160              124.020160   \n",
      "\n",
      "       start_distance_to_goal-1  end_distance_to_goal-1  \\\n",
      "count             727256.000000           727256.000000   \n",
      "mean                  65.437581               65.477622   \n",
      "std                   22.874273               23.434210   \n",
      "min                    0.000000                0.000000   \n",
      "25%                   48.826222               48.010416   \n",
      "50%                   66.910388               66.189123   \n",
      "75%                   81.599632               81.394103   \n",
      "max                  124.020160              124.020160   \n",
      "\n",
      "       start_distance_to_goal-2  end_distance_to_goal-2  \\\n",
      "count             726806.000000           726806.000000   \n",
      "mean                  65.038207               65.914496   \n",
      "std                   23.023832               23.401543   \n",
      "min                    0.000000                0.000000   \n",
      "25%                   48.166378               48.662100   \n",
      "50%                   66.483081               66.610810   \n",
      "75%                   81.320354               81.859636   \n",
      "max                  124.020160              124.020160   \n",
      "\n",
      "       start_angle_to_goal-0  end_angle_to_goal-0  start_angle_to_goal-1  \\\n",
      "count          727702.000000        727702.000000          727256.000000   \n",
      "mean                4.475524             4.056574               4.752531   \n",
      "std                10.100031             9.368569               9.787673   \n",
      "min                 0.000000             0.000000               0.000000   \n",
      "25%                 1.000000             1.000000               1.047619   \n",
      "50%                 2.000000             1.000000               1.933333   \n",
      "75%                 4.000000             3.000000               4.000000   \n",
      "max               105.000000           105.000000             105.000000   \n",
      "\n",
      "       end_angle_to_goal-1  start_angle_to_goal-2  end_angle_to_goal-2  \n",
      "count        727256.000000          726806.000000        726806.000000  \n",
      "mean              4.636760               4.688345             4.661557  \n",
      "std               9.635794               9.671659             9.657810  \n",
      "min               0.000000               0.000000             0.000000  \n",
      "25%               1.021277               1.035877             1.041667  \n",
      "50%               1.850000               1.909091             1.888889  \n",
      "75%               3.894737               3.956522             3.909091  \n",
      "max             105.000000             105.000000           105.000000  \n",
      "\n",
      "Label distribution:\n",
      "scores\n",
      "False    727702\n",
      "Name: count, dtype: int64\n",
      "Positive rate: 0.0\n",
      "scores training accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Check if features exist\n",
    "print(\"Features in training set:\", features)\n",
    "print(\"Missing features:\", [f for f in features if f not in df_X_train.columns])\n",
    "print(\"\\nFeature stats:\")\n",
    "print(df_X_train[features].describe())\n",
    "\n",
    "# Check label distribution\n",
    "print(\"\\nLabel distribution:\")\n",
    "print(df_y_train['scores'].value_counts())\n",
    "print(\"Positive rate:\", df_y_train['scores'].mean())\n",
    "\n",
    "# Check training accuracy\n",
    "for label in labels:\n",
    "    model = models[label]\n",
    "    train_preds = model.predict(df_X_train[features])\n",
    "    train_acc = (train_preds == df_y_train[label].values).mean()\n",
    "    print(f\"{label} training accuracy: {train_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scores\n",
       "False    80856\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_train['scores'].value_counts()\n",
    "df_y_test['scores'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute base rate probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell computes the *base rate* or *prior probability* of each class label in the training set. We use the *base rate* as a naive estimate for each example in the test set being true to establish a baseline for the evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_rates = pd.DataFrame({\n",
    "    label:np.full(len(df_y_test[label]), df_y_train[label].mean()) for label in labels\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   scores\n",
       "0     0.0\n",
       "1     0.0\n",
       "2     0.0\n",
       "3     0.0\n",
       "4     0.0\n",
       "5     0.0\n",
       "6     0.0\n",
       "7     0.0\n",
       "8     0.0\n",
       "9     0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base_rates.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Brier score loss for goal scored model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell computes the [Brier loss score](https://en.wikipedia.org/wiki/Brier_score) for the base rate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "missing a required argument: 'y_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mbrier_score_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf_y_test\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mscores\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_prob\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf_base_rates\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mscores\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anma10\\PycharmProjects\\fot-valuing-actions\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:196\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m params = \u001b[43mfunc_sig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m params.apply_defaults()\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# ignore self/cls and positional/keyword markers\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\inspect.py:3212\u001b[39m, in \u001b[36mSignature.bind\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3207\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, /, *args, **kwargs):\n\u001b[32m   3208\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[32m   3209\u001b[39m \u001b[33;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[32m   3210\u001b[39m \u001b[33;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[32m   3211\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3212\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\inspect.py:3182\u001b[39m, in \u001b[36mSignature._bind\u001b[39m\u001b[34m(self, args, kwargs, partial)\u001b[39m\n\u001b[32m   3175\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m   3176\u001b[39m     \u001b[38;5;66;03m# We have no value for this parameter.  It's fine though,\u001b[39;00m\n\u001b[32m   3177\u001b[39m     \u001b[38;5;66;03m# if it has a default value, or it is an '*args'-like\u001b[39;00m\n\u001b[32m   3178\u001b[39m     \u001b[38;5;66;03m# parameter, left alone by the processing of positional\u001b[39;00m\n\u001b[32m   3179\u001b[39m     \u001b[38;5;66;03m# arguments.\u001b[39;00m\n\u001b[32m   3180\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m partial \u001b[38;5;129;01mand\u001b[39;00m param.kind != _VAR_POSITIONAL \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m   3181\u001b[39m                                         param.default \u001b[38;5;129;01mis\u001b[39;00m _empty):\n\u001b[32m-> \u001b[39m\u001b[32m3182\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mmissing a required argument: \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[33m'\u001b[39m. \\\n\u001b[32m   3183\u001b[39m                         \u001b[38;5;28mformat\u001b[39m(arg=param_name)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3185\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3186\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m param.kind == _POSITIONAL_ONLY:\n\u001b[32m   3187\u001b[39m         \u001b[38;5;66;03m# This should never happen in case of a properly built\u001b[39;00m\n\u001b[32m   3188\u001b[39m         \u001b[38;5;66;03m# Signature object (but let's have this check here\u001b[39;00m\n\u001b[32m   3189\u001b[39m         \u001b[38;5;66;03m# to ensure correct behaviour just in case)\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: missing a required argument: 'y_proba'"
     ]
    }
   ],
   "source": [
    "brier_score_loss(\n",
    "    y_true=df_y_test['scores'],\n",
    "    y_prob=df_base_rates['scores']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell computes the [Brier loss score](https://en.wikipedia.org/wiki/Brier_score) for the predictions by the learned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brier_score_loss(\n",
    "    y_true=df_y_test['scores'],\n",
    "    y_prob=df_predictions['scores']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Brier score loss for goal conceded model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell computes the [Brier loss score](https://en.wikipedia.org/wiki/Brier_score) for the base rate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brier_score_loss(\n",
    "#     y_true=df_y_test['concedes'],\n",
    "#     y_prob=df_base_rates['concedes']\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell computes the [Brier loss score](https://en.wikipedia.org/wiki/Brier_score) for the predictions by the learned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brier_score_loss(\n",
    "#     y_true=df_y_test['concedes'],\n",
    "#     y_prob=df_predictions['concedes']\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot calibration curve and probability histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell creates a plot to show both a calibration curve and a probability histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(\n",
    "    nrows=2,\n",
    "    ncols=1,\n",
    "    figsize=(8, 8),\n",
    "    gridspec_kw={\n",
    "        'height_ratios': [3, 1]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell plots the *calibration curve* for the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_calibration_curve(\n",
    "    y_true=df_y_test['scores'],\n",
    "    probas_list=[df_predictions['scores'].tolist()],\n",
    "    clf_names=['Goal scored model'],\n",
    "    n_bins=10,\n",
    "    ax=ax1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell plots the histogram of the predictions produced by the trained model. Clearly, the majority of the examples is *negative*, which means that the start of the calibration curve is extremely important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions['scores'].plot.hist(\n",
    "    range=(0, 1),\n",
    "    bins=10,\n",
    "    ax=ax2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train *accurate* models, we perform a *grid search* over different combinations of parameter values for the most important hyperparameters for the learning algorithm. We will focus on the number of estimators and the maximum depth of the decision trees although more hyperparameters influence the performance of the trained models. The more combinations of parameter values need to be explored, the longer the *grid search* will take.\n",
    "\n",
    "Furthermore, restricting the number of estimators (i.e., the number of decision trees) and the maximum depth of the decision trees is an important mechanism to reduce the complexity of the trained models and thus also to avoid overfitting on the training data. The more decision trees that the learning algorithm can use and the deeper these decision trees can become, the more opportunities the learning algorithm has to *memorize* the training data rather than to discover patterns that generalize to the unseen test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell trains an XGBoost classifier for each label by trying different combinations of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtime\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodels_cv = \u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mfor label in tqdm(labels):\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    model = GridSearchCV(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        estimator=XGBClassifier(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            eval_metric=\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlogloss\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            use_label_encoder=False,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        ),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        param_grid=\u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mn_estimators\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m: [50, 100],\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmax_depth\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m: [3, 4]\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        },\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        scoring=\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mneg_brier_score\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        refit=True,  # train final model on full training set using best hyperparameters\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        verbose=10,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        n_jobs=1\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    )\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    model.fit(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        X=df_X_train[features],\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        y=df_y_train[label]\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    )\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    models_cv[label] = model\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anma10\\PycharmProjects\\fot-valuing-actions\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2572\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2570\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m   2571\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2572\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2574\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2575\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2576\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2577\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anma10\\PycharmProjects\\fot-valuing-actions\\venv\\Lib\\site-packages\\IPython\\core\\magics\\execution.py:1447\u001b[39m, in \u001b[36mExecutionMagics.time\u001b[39m\u001b[34m(self, line, cell, local_ns)\u001b[39m\n\u001b[32m   1445\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m interrupt_occured:\n\u001b[32m   1446\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exit_on_interrupt \u001b[38;5;129;01mand\u001b[39;00m captured_exception:\n\u001b[32m-> \u001b[39m\u001b[32m1447\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m captured_exception\n\u001b[32m   1448\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1449\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anma10\\PycharmProjects\\fot-valuing-actions\\venv\\Lib\\site-packages\\IPython\\core\\magics\\execution.py:1411\u001b[39m, in \u001b[36mExecutionMagics.time\u001b[39m\u001b[34m(self, line, cell, local_ns)\u001b[39m\n\u001b[32m   1409\u001b[39m st = clock2()\n\u001b[32m   1410\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1411\u001b[39m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_ns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1412\u001b[39m     out = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1413\u001b[39m     \u001b[38;5;66;03m# multi-line %%time case\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<timed exec>:2\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "models_cv = {}\n",
    "for label in tqdm(labels):\n",
    "    model = GridSearchCV(\n",
    "        estimator=XGBClassifier(\n",
    "            eval_metric='logloss',\n",
    "            use_label_encoder=False,\n",
    "        ),\n",
    "        param_grid={\n",
    "            'n_estimators': [50, 100],\n",
    "            'max_depth': [3, 4]\n",
    "        },\n",
    "        scoring='neg_brier_score',\n",
    "        refit=True,  # train final model on full training set using best hyperparameters\n",
    "        verbose=10,\n",
    "        n_jobs=1\n",
    "    )\n",
    "    model.fit(\n",
    "        X=df_X_train[features],\n",
    "        y=df_y_train[label]\n",
    "    )\n",
    "    models_cv[label] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** We have considered a manually selected set of features to represent the game states. In addition to optimizing the hyperparameters for the learning algorithm, we could also optimize the set of features to be considered by the learning algorithm. However, the XGBoost algorithm should be able to figure out by itself which features are most important to include in the model by the nature of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell estimates the probabilities for each label using the trained *baseline* models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_predictions_cv = {}\n",
    "for label in tqdm(labels):\n",
    "    model = models_cv[label]\n",
    "    probabilities = model.predict_proba(\n",
    "        df_X_test[features]\n",
    "    )\n",
    "    predictions = probabilities[:, 1]\n",
    "    dfs_predictions_cv[label] = pd.Series(predictions, index=df_X_test.index)\n",
    "df_predictions_cv = pd.concat(dfs_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Brier score loss for goal scored model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell computes the [Brier loss score](https://en.wikipedia.org/wiki/Brier_score) for the base rate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brier_score_loss(\n",
    "    y_true=df_y_test['scores'],\n",
    "    y_prob=df_base_rates['scores']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell computes the [Brier loss score](https://en.wikipedia.org/wiki/Brier_score) for the predictions by the learned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brier_score_loss(\n",
    "    y_true=df_y_test['scores'],\n",
    "    y_prob=df_predictions_cv['scores']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Brier score loss for goal conceded model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell computes the [Brier loss score](https://en.wikipedia.org/wiki/Brier_score) for the base rate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brier_score_loss(\n",
    "#     y_true=df_y_test['concedes'],\n",
    "#     y_prob=df_base_rates['concedes']\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell computes the [Brier loss score](https://en.wikipedia.org/wiki/Brier_score) for the predictions by the learned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brier_score_loss(\n",
    "#     y_true=df_y_test['concedes'],\n",
    "#     y_prob=df_predictions_cv['concedes']\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot calibration curve and probability histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell creates a plot to show both a calibration curve and a probability histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_cv, (ax1_cv, ax2_cv) = plt.subplots(\n",
    "    nrows=2,\n",
    "    ncols=1,\n",
    "    figsize=(8, 8),\n",
    "    gridspec_kw={\n",
    "        'height_ratios': [3, 1]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell plots the *calibration curve* for the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_calibration_curve(\n",
    "    y_true=df_y_test['scores'],\n",
    "    probas_list=[df_predictions_cv['scores'].tolist()],\n",
    "    clf_names=['Goal scored model'],\n",
    "    n_bins=10,\n",
    "    ax=ax1_cv\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell plots the histogram of the predictions produced by the trained model. Clearly, the majority of the examples is *negative*, which means that the start of the calibration curve is extremely important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions_cv['scores'].plot.hist(\n",
    "    range=(0, 1),\n",
    "    bins=10,\n",
    "    ax=ax2_cv\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Calibrate probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the trained model produces poorly calibrated probability estimates, the probability estimates can be re-calibrated using [CalibratedClassifierCV](https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html), which performs probability calibration with isotonic regression or logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct final classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have found the *best* feature set and *best* hyperparameters for the learning algorithm, we can learn the final model.\n",
    "\n",
    "1. If we use `GridSearchCV` and the `refit` parameter was set to `True`, we can retrieve the *final* model, which has been re-trained on the entire training set, by accessing the `best_estimator_` attribute of the object.\n",
    "2. We can manually train the *final* model by creating a `XGBClassifier` object using the *best* hyperparameters and calling the `fit` method with the entire training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Retrieve classifier from grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = models_cv['scores']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell shows the *best* hyperparameter combination that was found using the *grid search*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(\n",
    "    model_scores.best_params_\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell shows the full results of the *grid search*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    model_scores.cv_results_\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell shows the hyperparameters that were used to re-train the model on the entire training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(\n",
    "    model_scores.best_estimator_.get_params()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell retrieves the final `XGBClassifier` object from the `GridSearchCV` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores_final = model_scores.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Train classifier using optimal hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell constructs a new `XGBoostClassifier` object using the *best* hyperparameters that were found by the *grid search*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores_final = XGBClassifier(\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False,\n",
    "    n_estimators=100,\n",
    "    max_depth=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell fits the `XGBoostClassifier` object on the entire training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores_final.fit(\n",
    "    X=df_X_train[features],\n",
    "    y=df_y_train[label]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "498.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
